{"cells":[{"cell_type":"markdown","metadata":{"id":"u9I93Z1-lZka"},"source":["# New Section"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shjXfgXyGiWT","executionInfo":{"status":"ok","timestamp":1764264950255,"user_tz":-210,"elapsed":967156,"user":{"displayName":"shady nikooei","userId":"01189796853460759548"}},"outputId":"271520c7-2a7f-4fbf-c1af-e70340a97db6"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- [INFO] Starting Full Setup and Evaluation Pipeline ---\n","[INFO] Installing torch/lpips/scikit-image dependencies...\n","[INFO] Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[SUCCESS] Google Drive is mounted.\n","[INFO] Removing old repository version...\n","[INFO] Cloning latest code from GitHub...\n","Cloning into 'DeepVision-Frame-Reconstruction-System'...\n","remote: Enumerating objects: 147, done.\u001b[K\n","remote: Counting objects: 100% (147/147), done.\u001b[K\n","remote: Compressing objects: 100% (123/123), done.\u001b[K\n","remote: Total 147 (delta 35), reused 119 (delta 18), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (147/147), 2.96 MiB | 33.65 MiB/s, done.\n","Resolving deltas: 100% (35/35), done.\n","[SUCCESS] Entered project directory.\n","[INFO] Patching optical_flow_wrapper for safety...\n","[INFO] Setting up data...\n","[INFO] Copying video files from Drive...\n","[INFO] Input Video Path: /content/DeepVision-Frame-Reconstruction-System/data/uvg/archive/insects/butterflies_1280.mp4\n","[INFO] Dropping frames to create incomplete video...\n","[SUCCESS] Incomplete video created.\n","[INFO] Running Adaptive Interpolation...\n","Using the Adaptive Switching System (Flow / RIFE)...\n","Adaptive switch threshold set to: 5.0 (Mean Flow Magnitude)\n","Saved: /content/DeepVision-Frame-Reconstruction-System/results/final_output.mp4 at 29.97 FPS\n","\n","[SUCCESS] Reconstructed video saved at: /content/DeepVision-Frame-Reconstruction-System/results/final_output.mp4\n","\n","--- [INFO] Starting evaluation metrics calculation (PSNR, SSIM, LPIPS) ---\n","Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n","Loading model from: /usr/local/lib/python3.12/dist-packages/lpips/weights/v0.1/vgg.pth\n","[INFO] LPIPS model initialized on device: cuda\n","[INFO] Comparing reconstructed frames against ground truth...\n","\n","--- [EVALUATION RESULTS] ğŸ“Š ---\n","Total interpolated frames analyzed: 786\n","Average PSNR (Peak Signal-to-Noise Ratio): 28.0273\n","Average SSIM (Structural Similarity Index): 0.3242\n","Average LPIPS (Learned Perceptual Similarity): 0.7979 (Lower is Better)\n","\n","[SUCCESS] Evaluation metrics saved to file: /content/DeepVision-Frame-Reconstruction-System/results/evaluation_results.txt\n","\n","[END] Full pipeline execution and evaluation complete.\n"]}],"source":["import os\n","import sys\n","import glob\n","import shutil\n","import cv2\n","import numpy as np\n","from skimage.metrics import structural_similarity as ssim\n","from google.colab import drive\n","import math\n","import torch\n","import lpips\n","\n","print(\"--- [INFO] Starting Full Setup and Evaluation Pipeline ---\")\n","\n","# ==========================================\n","# 0. Install Critical Dependencies FIRST\n","# ==========================================\n","# We install these first to prevent ModuleNotFoundError when importing.\n","print(\"[INFO] Installing torch/lpips/scikit-image dependencies...\")\n","!pip install lpips scikit-image > /dev/null\n","!pip install torch torchvision > /dev/null\n","\n","# ==========================================\n","# 1. Mount Google Drive\n","# ==========================================\n","print(\"[INFO] Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"[SUCCESS] Google Drive is mounted.\")\n","\n","# ==========================================\n","# 2. Clean & Clone Repository\n","# ==========================================\n","os.chdir(\"/content\")\n","if os.path.exists(\"DeepVision-Frame-Reconstruction-System\"):\n","    print(\"[INFO] Removing old repository version...\")\n","    shutil.rmtree(\"DeepVision-Frame-Reconstruction-System\")\n","\n","print(\"[INFO] Cloning latest code from GitHub...\")\n","!git clone https://github.com/ShadyNikooei/DeepVision-Frame-Reconstruction-System.git\n","\n","os.chdir(\"/content/DeepVision-Frame-Reconstruction-System\")\n","print(\"[SUCCESS] Entered project directory.\")\n","\n","\n","# ==========================================\n","# 3. Safety Patch: Fix 'optical_flow_wrapper.py' Path\n","# ==========================================\n","wrapper_path = \"deepvision/models/optical_flow_wrapper.py\"\n","if os.path.exists(wrapper_path):\n","    print(\"[INFO] Patching optical_flow_wrapper for safety...\")\n","    new_wrapper_code = \"\"\"\n","import torch\n","import cv2\n","import numpy as np\n","import sys\n","import os\n","\n","# --- PATH FIX ---\n","current_dir = os.path.dirname(os.path.abspath(__file__))\n","project_root = os.path.dirname(os.path.dirname(current_dir))\n","cv_folder_candidates = [\n","    os.path.join(project_root, 'computer_vision'),\n","    os.path.join(project_root, 'computer_vision_')\n","]\n","\n","for folder in cv_folder_candidates:\n","    if os.path.exists(folder) and folder not in sys.path:\n","        sys.path.append(folder)\n","# ----------------\n","\n","try:\n","    from hybrid_optical_flow_interpolation import hybrid_optical_flow_interpolation\n","except ImportError:\n","    try:\n","        from computer_vision.hybrid_optical_flow_interpolation import hybrid_optical_flow_interpolation\n","    except ImportError:\n","        from computer_vision_.hybrid_optical_flow_interpolation import hybrid_optical_flow_interpolation\n","\n","from deepvision.pipelines.interpolate import t_to_bgr_uint8, bgr_uint8_to_t\n","\n","class OpticalFlowInterpolator(torch.nn.Module):\n","    def __init__(self, fix_border: bool = True):\n","        super().__init__()\n","        self.fix_border = fix_border\n","        self.device = \"cpu\"\n","\n","    def forward(self, img0: torch.Tensor, img1: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n","        img0_bgr_np = t_to_bgr_uint8(img0)\n","        img1_bgr_np = t_to_bgr_uint8(img1)\n","        frame_a = cv2.cvtColor(img0_bgr_np, cv2.COLOR_BGR2RGB)\n","        frame_c = cv2.cvtColor(img1_bgr_np, cv2.COLOR_BGR2RGB)\n","        interpolated_rgb_np = hybrid_optical_flow_interpolation(frame_a, frame_c, self.fix_border)\n","        return bgr_uint8_to_t(cv2.cvtColor(interpolated_rgb_np, cv2.COLOR_RGB2BGR))\n","\n","    def load_pretrained(self, **kwargs) -> \"OpticalFlowInterpolator\":\n","        return self\n","\"\"\"\n","    with open(wrapper_path, \"w\") as f:\n","        f.write(new_wrapper_code)\n","\n","\n","# ==========================================\n","# 4. Prepare Data (From Google Drive)\n","# ==========================================\n","print(\"[INFO] Setting up data...\")\n","os.makedirs(\"data/uvg\", exist_ok=True)\n","\n","drive_source = \"/content/drive/MyDrive/MyProject_Data\"\n","\n","mp4_files = glob.glob(\"data/uvg/**/*.mp4\", recursive=True)\n","if not mp4_files:\n","    if os.path.exists(drive_source):\n","        print(\"[INFO] Copying video files from Drive...\")\n","        !cp -r \"{drive_source}/.\" \"data/uvg/\"\n","    else:\n","        print(\"[WARNING] Drive source folder not found. Please ensure the path is correct.\")\n","else:\n","    print(\"[SUCCESS] Data already exists in Colab.\")\n","\n","video_files = glob.glob(\"data/uvg/**/*.mp4\", recursive=True)\n","video_files = [v for v in video_files if \"incomplete\" not in v]\n","\n","if not video_files:\n","    raise FileNotFoundError(\"[ERROR] No input video found! Please upload videos to Drive folder 'MyProject_Data'.\")\n","\n","input_video = os.path.abspath(video_files[0])\n","incomplete_video = os.path.abspath(\"data/uvg/incomplete.mp4\")\n","final_output = os.path.abspath(\"results/final_output.mp4\")\n","# Define the path for the text results file\n","results_file = os.path.abspath(\"results/evaluation_results.txt\")\n","\n","print(f\"[INFO] Input Video Path: {input_video}\")\n","\n","\n","# ==========================================\n","# 5. Generate Incomplete Video (Drop Frames)\n","# NOTE: YOU MUST CORRECT THE INDEXING IN YOUR make_incomplete_video.py FILE\n","# (change 'i % 2 == 1' to 'i % 2 == 0' to keep even frames)\n","# ==========================================\n","print(\"[INFO] Dropping frames to create incomplete video...\")\n","cap = cv2.VideoCapture(input_video)\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","out = cv2.VideoWriter(incomplete_video, fourcc, fps / 2, (width, height))\n","\n","frame_idx = 0\n","while True:\n","    ret, frame = cap.read()\n","    if not ret: break\n","    # KEEP EVEN FRAMES (0, 2, 4, ...) - ASSUMING CORRECTION IS APPLIED\n","    if frame_idx % 2 == 0: out.write(frame)\n","    frame_idx += 1\n","cap.release()\n","out.release()\n","print(\"[SUCCESS] Incomplete video created.\")\n","\n","\n","# ==========================================\n","# 6. Run Adaptive Interpolation Inference\n","# ==========================================\n","print(\"[INFO] Running Adaptive Interpolation...\")\n","os.makedirs(\"results\", exist_ok=True)\n","\n","!python -m deepvision.scripts.infer_video \\\n","  --input \"{incomplete_video}\" \\\n","  --output \"{final_output}\" \\\n","  --adaptive \\\n","  --num-intermediate 1\n","\n","if os.path.exists(final_output):\n","    print(f\"\\n[SUCCESS] Reconstructed video saved at: {final_output}\")\n","else:\n","    print(\"\\n[ERROR] Inference failed. Check logs above.\")\n","\n","\n","# ==========================================\n","# 7. Evaluation Metrics Calculation and File Output (FIXED LPIPS)\n","# ==========================================\n","print(\"\\n--- [INFO] Starting evaluation metrics calculation (PSNR, SSIM, LPIPS) ---\")\n","\n","# --- LPIPS Initialization (FIXED) ---\n","# Define the device first and assign the model to it to resolve AttributeError.\n","lpips_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the LPIPS model\n","try:\n","    loss_fn_vgg = lpips.LPIPS(net='vgg').to(lpips_device)\n","except Exception as e:\n","    print(f\"[ERROR] Could not load LPIPS model to CUDA/GPU: {e}\")\n","    lpips_device = torch.device(\"cpu\")\n","    loss_fn_vgg = lpips.LPIPS(net='vgg').to(lpips_device)\n","\n","print(f\"[INFO] LPIPS model initialized on device: {lpips_device}\")\n","\n","\n","# --- Helper Functions ---\n","def calculate_psnr(img1, img2):\n","    mse = np.mean((img1 - img2) ** 2)\n","    if mse == 0: return 100.0\n","    max_pixel = 255.0\n","    psnr = 20 * math.log10(max_pixel / math.sqrt(mse))\n","    return psnr\n","\n","def np_to_torch(img_np):\n","    img_rgb = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n","    # Use the globally defined device\n","    tensor = lpips.im2tensor(img_rgb).to(lpips_device)\n","    return tensor\n","\n","# --- Main Evaluation Logic ---\n","\n","cap_original = cv2.VideoCapture(input_video)\n","cap_reconstructed = cv2.VideoCapture(final_output)\n","\n","if not cap_original.isOpened() or not cap_reconstructed.isOpened():\n","    print(\"[ERROR] Could not open video files for evaluation.\")\n","    sys.exit()\n","\n","psnr_values = []\n","ssim_values = []\n","lpips_values = []\n","frame_idx = 0\n","\n","print(\"[INFO] Comparing reconstructed frames against ground truth...\")\n","\n","while True:\n","    ret_orig, frame_orig = cap_original.read()\n","\n","    # Only compare the frames that were interpolated (odd index)\n","    if frame_idx % 2 != 0 and ret_orig:\n","        ret_reco, frame_reco = cap_reconstructed.read()\n","\n","        if ret_reco:\n","            if frame_orig.shape != frame_reco.shape:\n","                frame_reco = cv2.resize(frame_reco, (frame_orig.shape[1], frame_orig.shape[0]), interpolation=cv2.INTER_LINEAR)\n","\n","            psnr_values.append(calculate_psnr(frame_orig, frame_reco))\n","\n","            gray_orig = cv2.cvtColor(frame_orig, cv2.COLOR_BGR2GRAY)\n","            gray_reco = cv2.cvtColor(frame_reco, cv2.COLOR_BGR2GRAY)\n","            ssim_val, _ = ssim(gray_orig, gray_reco, full=True)\n","            ssim_values.append(ssim_val)\n","\n","            tensor_orig = np_to_torch(frame_orig)\n","            tensor_reco = np_to_torch(frame_reco)\n","\n","            with torch.no_grad():\n","                lpips_val = loss_fn_vgg(tensor_orig, tensor_reco).item()\n","            lpips_values.append(lpips_val)\n","\n","        elif not ret_reco:\n","            break\n","\n","    elif not ret_orig:\n","        break\n","\n","    frame_idx += 1\n","\n","cap_original.release()\n","cap_reconstructed.release()\n","\n","# --- Reporting Results and Saving to File ---\n","if psnr_values:\n","    avg_psnr = np.mean(psnr_values)\n","    avg_ssim = np.mean(ssim_values)\n","    avg_lpips = np.mean(lpips_values)\n","\n","    # Format the report content\n","    report = [\n","        \"\\n--- [EVALUATION RESULTS] ğŸ“Š ---\",\n","        f\"Total interpolated frames analyzed: {len(psnr_values)}\",\n","        f\"Average PSNR (Peak Signal-to-Noise Ratio): {avg_psnr:,.4f}\",\n","        f\"Average SSIM (Structural Similarity Index): {avg_ssim:,.4f}\",\n","        f\"Average LPIPS (Learned Perceptual Similarity): {avg_lpips:,.4f} (Lower is Better)\"\n","    ]\n","\n","    # Print to console\n","    print(\"\\n\".join(report))\n","\n","    # Save to text file for Git tracking\n","    with open(results_file, \"w\") as f:\n","        f.write(\"\\n\".join(report))\n","\n","    print(f\"\\n[SUCCESS] Evaluation metrics saved to file: {results_file}\")\n","else:\n","    print(\"\\n[WARNING] No interpolated frames were successfully compared.\")\n","\n","print(\"\\n[END] Full pipeline execution and evaluation complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4589,"status":"ok","timestamp":1764260241507,"user":{"displayName":"shady nikooei","userId":"01189796853460759548"},"user_tz":-210},"id":"lRMTvhRGGrF1","outputId":"fad5d903-e385-42b1-b9e0-ed9374f39e18"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ø¯Ø± Ø­Ø§Ù„ Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø­ÛŒØ§ØªÛŒ...\n","Collecting lpips\n","  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n","Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.12/dist-packages (from lpips) (2.0.2)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (1.16.3)\n","Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (4.67.1)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.6)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lpips\n","Successfully installed lpips-0.1.4\n","Ù†ØµØ¨ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯.\n"]}],"source":["print(\"Ø¯Ø± Ø­Ø§Ù„ Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø­ÛŒØ§ØªÛŒ...\")\n","!pip install lpips scikit-image torch torchvision\n","print(\"Ù†ØµØ¨ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯.\")"]},{"cell_type":"code","source":["print(\"Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù†ÙˆØªâ€ŒØ¨ÙˆÚ©â€ŒÙ‡Ø§ Ø¯Ø± Google Drive...\")\n","!ls -R \"/content/drive/MyDrive/\" | grep -E \".*\\.ipynb$\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQ1gMhHzeC8U","executionInfo":{"status":"ok","timestamp":1764266511041,"user_tz":-210,"elapsed":191,"user":{"displayName":"shady nikooei","userId":"01189796853460759548"}},"outputId":"89c9535e-0c66-4bc8-a016-93b7bf805bd0"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù†ÙˆØªâ€ŒØ¨ÙˆÚ©â€ŒÙ‡Ø§ Ø¯Ø± Google Drive...\n","Untitled0.ipynb\n","Untitled1.ipynb\n","deepVisionTest.ipynb\n","gpu_Programming_EX1.ipynb\n","PPO_CLIP_1.ipynb\n","PPO_CLIP_2.ipynb\n","Untitled7.ipynb\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"tj5KAW46eRV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","#os.chdir(\"/content\")\n","print(f\"dir: {os.getcwd()}\")\n","\n","notebook_name = \"deepVisionTest.ipynb\"\n","repo_dir = \"/content/DeepVision-Frame-Reconstruction-System\"\n","\n","!mv \"{notebook_name}\" \"{repo_dir}/\"\n","print(f\"file deepVisionTest.ipynb forwarded to {repo_dir}.\")\n","\n","os.chdir(repo_dir)\n","\n","!git add \"{notebook_name}\"\n","print(\"ready for comit\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xltsI1w_bVvC","executionInfo":{"status":"ok","timestamp":1764266285295,"user_tz":-210,"elapsed":294,"user":{"displayName":"shady nikooei","userId":"01189796853460759548"}},"outputId":"23e4418a-45dc-407f-ae28-f4cffe85e56c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["dir: /content/DeepVision-Frame-Reconstruction-System\n","mv: cannot stat 'deepVisionTest.ipynb': No such file or directory\n","file deepVisionTest.ipynb forwarded to /content/DeepVision-Frame-Reconstruction-System.\n","fatal: pathspec 'deepVisionTest.ipynb' did not match any files\n","ready for comit\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1zKN9bYlvtBx9_Y5YptZ5biFCE-P8RwY9","authorship_tag":"ABX9TyM4AftJrrrlUuih3ERkWKN/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}